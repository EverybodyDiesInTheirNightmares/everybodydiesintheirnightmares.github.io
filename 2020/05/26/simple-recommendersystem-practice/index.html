<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
    
    <title>基于协同过滤的音乐推荐系统实践 - 双绞麻痹</title>
    <meta charset="utf-8">
    
    <meta name="title" content="基于协同过滤的音乐推荐系统实践 - 双绞麻痹">
    <meta name="description" content="">
    <meta property="og:image" content="/favicon.png">
    <meta property="og:image:width" content="200" />
    <meta property="og:image:height" content="200" />
    
    <link href="https://fonts.googleapis.com/css2?family=Source+Serif+Pro:wght@400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Source Serif Pro', 'Source Han Serif SC', 'Noto Serif CJK SC', 'Noto Serif SC', serif;
        }
    </style>
    <link rel="shortcut icon" href="/favicon.png">
    
    <link rel="stylesheet"
        href="https://version2.oss-cn-hangzhou.aliyuncs.com/source/js/arduino-light.min.css">
    <script src="https://version2.oss-cn-hangzhou.aliyuncs.com/source/js/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    
    
    
<link rel="stylesheet" href="/css/style.css">

    
<script src="/js/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.1.1"><link rel="alternate" href="/atom.xml" title="双绞麻痹" type="application/atom+xml">
</head>

<body>
    <header class="header">
    <div class="blog-title">
        <a href="/" class="logo">双绞麻痹</a>
    </div>
    <nav class="navbar">
        <ul class="menu">
            
            
            
            <li class="menu-item">
                
                <a href="/archives" class="menu-item-link">归档</a>
                
            </li>
            
            
            
            <li class="menu-item">
                
                <a href="/about" class="menu-item-link">关于</a>
                
            </li>
            
            
            
            <li class="menu-item">
                
                <a href="/been2" class="menu-item-link">去过</a>
                
            </li>
            
        </ul>
    </nav>
</header>
    <main class="main">
        <article class="post">
    <div class="post-title">
        <h1 class="title">基于协同过滤的音乐推荐系统实践</h2>
    </div>
    <div class="post-content">
        <blockquote>
<p>废话：近年来，「人工智能/大数据/机器学习/区块链」等等词汇越发「甚嚣尘上」(误)。作为一个仅仅对web开发有些许了解并且不想成为码畜的普通计算机本科生，虽然顶着「计算机科学与技术」这样一个看似响亮的名号，但说实在的，我对上述词汇的认知可以说是「聊胜于无」(误)，直到本学期学校开了人工智能的相关课程，才逐渐对相关信息有所了解，也直到完成本次课程实践作业，我或许才算得上真正的入门「机器学习」。</p>
</blockquote>
<h3 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h3><blockquote>
<p>据报道 [1]，中国有超过 9.77 亿人每周都听音乐，而 66%的人通过流媒体来听音乐。为了 给用户提供更好的体验，如何为用户推荐喜爱的音乐就变得非常重要。本项目使用的数据 集来自 Last.fm 音乐网站 [2]，数据集在 2011 推荐系统会议(ACM RecSys)中发布。——人工智能实践课程项目一 音乐推荐系统</p>
</blockquote>
<blockquote>
<p>Recommenders: systems, sites and software that mine data to find stuff you’ll like——reddit</p>
</blockquote>
<blockquote>
<p>据报道，推荐系统给亚马逊带来了35%的销售收入，给Netflix带来了高达75%的消费，并且Youtube主页上60%的浏览来自推荐服务。——msra</p>
</blockquote>
<blockquote>
<p>完成课程目标(误，其实还是很感兴趣，不然也不会专门写博客) ——citizen5</p>
</blockquote>
<blockquote>
<p>通过本次项目实践，我们学会了如何为推荐系统预处理数据，通过相对简单的方法和第三方库实现了「协同过滤」和「随机梯度下降」，最终达到了普通人也能实现的「人工智能」。——总结</p>
</blockquote>
<h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3><h6 id="什么是推荐系统"><a href="#什么是推荐系统" class="headerlink" title="什么是推荐系统"></a>什么是推荐系统</h6><blockquote>
<p><strong>推荐系统</strong>是一种信息过滤系统，用于预测用户对物品的“评分”或“偏好”。[<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%8E%A8%E8%96%A6%E7%B3%BB%E7%B5%B1#cite_note-1">1]</a></p>
<p>推荐系统近年来非常流行，应用于各行各业。推荐的对象包括：电影、音乐、新闻、书籍、学术论文、搜索查询、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%88%86%E4%BC%97%E5%88%86%E7%B1%BB%E6%B3%95">分众分类</a>、以及其他产品。也有一些推荐系统专门为寻找专家[<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%8E%A8%E8%96%A6%E7%B3%BB%E7%B5%B1#cite_note-expertseer-2">2]</a>、合作者[<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%8E%A8%E8%96%A6%E7%B3%BB%E7%B5%B1#cite_note-collabseer-3">3]</a>、笑话、餐厅、美食、金融服务[<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%8E%A8%E8%96%A6%E7%B3%BB%E7%B5%B1#cite_note-financialrec-4">4]</a>、生命保险、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%B6%B2%E8%B7%AF%E4%BA%A4%E5%8F%8B">网络交友</a>，以及Twitter页面[<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%8E%A8%E8%96%A6%E7%B3%BB%E7%B5%B1#cite_note-twitterwtf-5">5]</a>设计。</p>
<p>推荐系统产生推荐列表的方式通常有两种：<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%8D%94%E5%90%8C%E9%81%8E%E6%BF%BE">协同过滤</a>以及<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/w/index.php?title=%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E6%8E%A8%E8%8D%90&action=edit&redlink=1">基于内容推荐</a>，或者基于个性化推荐。[<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%8E%A8%E8%96%A6%E7%B3%BB%E7%B5%B1#cite_note-6">6]</a> <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%8D%94%E5%90%8C%E9%81%8E%E6%BF%BE">协同过滤</a>方法根据用户历史行为（例如其购买的、选择的、评价过的物品等）结合其他用户的相似决策建立模型。这种模型可用于预测用户对哪些物品可能感兴趣（或用户对物品的感兴趣程度）。[<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%8E%A8%E8%96%A6%E7%B3%BB%E7%B5%B1#cite_note-Recommender2010-7">7]</a> <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/w/index.php?title=%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E6%8E%A8%E8%8D%90&action=edit&redlink=1">基于内容推荐</a>利用一些列有关物品的离散特征，推荐出具有类似性质的相似物品。[<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%8E%A8%E8%96%A6%E7%B3%BB%E7%B5%B1#cite_note-mooney99-8">8]</a>两种方法经常互相结合（参考<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/w/index.php?title=%E6%B7%B7%E5%90%88%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F&action=edit&redlink=1">混合推荐系统</a>）</p>
<p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%8D%94%E5%90%8C%E9%81%8E%E6%BF%BE">协同过滤</a>和<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/w/index.php?title=%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E6%8E%A8%E8%8D%90&action=edit&redlink=1">基于内容推荐</a>的区别可以比较两个流行的音乐推荐系统 — <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Last.fm">Last.fm</a> 和 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Pandora_Radio">Pandora Radio</a>.</p>
<ul>
<li>Last.fm 建立通过观察用户日常收听的乐队或歌手，并与其它用户的行为进行比对，建立一个“电台”，以此推荐歌曲。Last.fm 会播放不在用户曲库中，但其他相似用户经常会播放的其它音乐。鉴于这种方式利用了用户行为，因此可以认为它是协同过滤技术的一种应用范例。</li>
<li>Pandora 使用歌曲或者艺人的属性（由<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/w/index.php?title=%E9%9F%B3%E4%B9%90%E6%B5%81%E6%B4%BE%E9%A1%B9%E7%9B%AE&action=edit&redlink=1">音乐流派项目</a>提供的400个属性的子集）从而生成一个电台，其中的乐曲都有相似的属性。用户的反馈用于精化电台中的内容。在用户“不喜欢”某一歌曲时，弱化某一些属性；在用户喜欢某一歌曲时，强化另一些属性。这是一种基于内容推荐的方式。</li>
</ul>
<p>每一种系统都有其长处与弱点。在上面的例子中，为了提供精准推荐，Last.fm 需要大量用户信息。这是一个<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%86%B7%E5%95%9F%E5%8B%95">冷启动</a>问题，在协同过滤系统中是常见的问题[<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%8E%A8%E8%96%A6%E7%B3%BB%E7%B5%B1#cite_note-rubens2016-9">9]</a>[<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%8E%A8%E8%96%A6%E7%B3%BB%E7%B5%B1#cite_note-elahi2016-10">10]</a>[<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%8E%A8%E8%96%A6%E7%B3%BB%E7%B5%B1#cite_note-schein02-11">11]</a>。而 Pandora 启动时则仅需要很少信息，然而这种方法的局限性很大（例如，这类方法只能得出与原始种子相似的推荐）。</p>
<p>推荐系统是一种有效代替搜索算法的方式，因为他们帮助用户找到一些他们自己没有办法找到的物品。有趣的是，推荐系统在实现之时通常使用搜索引擎对非传统数据索引。——Wikipedia</p>
</blockquote>
<h6 id="推荐系统常用算法"><a href="#推荐系统常用算法" class="headerlink" title="推荐系统常用算法"></a>推荐系统常用算法</h6><blockquote>
<p>常用的推荐系统算法有五种，每一种都有其优点，不同场景下每一种算法效果会不一样。——zhan-bin</p>
<ul>
<li>1.基于内容的推荐</li>
<li>2.协同过滤推荐</li>
<li>3.基于关联规则的推荐</li>
<li>4.基于知识的推荐</li>
<li>5.混合推荐</li>
</ul>
</blockquote>
<h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><h6 id="推荐方法选型"><a href="#推荐方法选型" class="headerlink" title="推荐方法选型"></a>推荐方法选型</h6><p>在经过大量的资料查阅和长期的小组讨论后，我们最终决定采用「Collaborative Filtering」即「协同过滤」的推荐方法。</p>
<blockquote>
<p><strong>协同过滤</strong>，简单来说是利用某兴趣相投、拥有共同经验之群体的喜好来推荐用户感兴趣的信息，个人透过合作的机制给予信息相当程度的回应（如评分）并记录下来以达到过滤的目的进而帮助别人筛选信息，回应不一定局限于特别感兴趣的，特别不感兴趣信息的纪录也相当重要。协同过滤又可分为<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/w/index.php?title=%E8%A9%95%E6%AF%94&action=edit&redlink=1">评比</a>（rating）或者<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/w/index.php?title=%E7%BE%A4%E9%AB%94%E9%81%8E%E6%BF%BE&action=edit&redlink=1">群体过滤</a>（social filtering）。其后成为电子商务当中很重要的一环，即根据某顾客以往的购买行为以及从具有相似购买行为的顾客群的购买行为去推荐这个顾客其“可能喜欢的品项”，也就是借由社群的喜好提供个人化的信息、商品等的推荐服务。——Wikipedia</p>
</blockquote>
<p>我认为，通俗的来说，你可以这样理解协同过滤：在一个无聊的漫漫长夜里，你难以入睡并打开了某听歌软件，面对如此庞大的曲库你不知道要听些什么歌来衬托黑夜。这时，或许具备传说中「artificial intelligence」能力的听歌软件会获取和你具有相似行为的用户信息，又或许它获取了你对哪些歌曲点过红心，从而根据上述两种方式找到你或许会喜欢的歌曲。「伟大的协同过滤诞生了」。</p>
<blockquote>
<p>A lot of research has been done on collaborative filtering (CF), and most popular approaches are based on <strong>low-dimensional factor models</strong> (model based matrix factorization. I will discuss these in detail). The CF techniques are broadly divided into 2-types:——<a target="_blank" rel="noopener" href="https://towardsdatascience.com/@pgrover3?source=post_page-----100385c6dfe0----------------------">Prince Grover</a></p>
</blockquote>
<p>在查阅众多资料后，我认为协同过滤可以分为 两个大类：基于记忆「memory」的协同过滤（不知道怎么翻译更准确）和基于模型的协同过滤。而「Memory-Based Collaborative Filtering」，正是我在前文中所提到的「user-item filtering」和「 item-item filtering」，在此就不再引例。</p>
<p>而「基于模型的协同过滤」又基于「 matrix factorization」即「矩阵分解」，矩阵分解被用作一种在潜在变量分解和降维时的无人监管的学习方法，他比「Memory-Based Collaborative Filtering」更具有可扩展性和稀疏性。在查了矩阵分解的定义后我逐渐明白了到底什么是「基于模型的协同过滤」，但又被众多的定义和术语搞得云里雾里。那么有了矩阵分解或者说是「基于模型的协同过滤」后我们到底能做些什么呢？简而言之，我们可以通过「预测」的方式来模拟原始矩阵中的缺失条目，也就是下文中即将提到的「ratings」。</p>
<blockquote>
<h2 id="Collaborative-Filtering-CF"><a href="#Collaborative-Filtering-CF" class="headerlink" title="Collaborative Filtering (CF)"></a>Collaborative Filtering (CF)</h2><h3 id="Memory-Based-Collaborative-Filtering"><a href="#Memory-Based-Collaborative-Filtering" class="headerlink" title="Memory-Based Collaborative Filtering"></a>Memory-Based Collaborative Filtering</h3><p>Memory-Based CF methods can be divided into two sections: user-item filtering and item-item filtering. Here is the difference:</p>
<ul>
<li>Item-Item Collaborative Filtering: “Users who liked this item also liked …”</li>
<li>User-Item Collaborative Filtering: “Users who are similar to you (kinda like the twin you never knew you had) also liked …”</li>
</ul>
<p>Both methods require user-item matrix that contain the ratings for user u<em>u</em> for item i<em>i</em>. From that, you can calculate the similarity matrix.</p>
<p>The similarity values in Item-Item Collaborative Filtering are calculated by taking into account all users who have rated a pair of items.</p>
<p>For User-Item Collaborative Filtering, the similarity values are calculated by observing all items that are rated by a pair of users.</p>
<h3 id="Model-Based-Collaborative-Filtering"><a href="#Model-Based-Collaborative-Filtering" class="headerlink" title="Model-Based Collaborative Filtering"></a>Model-Based Collaborative Filtering</h3><p>Model-based CF methods are based on <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Matrix_factorization_(recommender_systems)">matrix factorization (MF)</a>. MF methods are used as an unsupervised learning method for latent variable decomposition and dimensionality reduction. They can handle scalability and sparsity problems better than Memory-based CF.</p>
<p>The goal of MF is to learn latent user preferences and item attributes from known ratings. Then use those variable to predict unknown ratings through the dot product of the latent features of users and items.</p>
<p>Matrix factorization restructures the user-item matrix into a low-rank matrix. You can represent it by the multiplication of two low-rank matrices, where the rows contain a vector of latent variables. You want this matrix to approximate the original matrix, as closely as possible, by multiplying the low-rank matrices together. That way, you predict the missing entries in the original matrix.</p>
</blockquote>
<h6 id="引用第三方库"><a href="#引用第三方库" class="headerlink" title="引用第三方库"></a>引用第三方库</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import graphlab as gl</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import math</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.metrics import accuracy_score</span><br><span class="line">from math import sqrt</span><br><span class="line">from sklearn.metrics import mean_squared_error</span><br></pre></td></tr></table></figure>

<h6 id="导入last-fm数据集并作预处理"><a href="#导入last-fm数据集并作预处理" class="headerlink" title="导入last.fm数据集并作预处理"></a>导入last.fm数据集并作预处理</h6><p>使用pd.read_csv()导入user_artists.dat和artists.dat，并将两个dframe合并为一个新的dframe:「ap」，并将weight重命名为playcount。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plays &#x3D; pd.read_csv(&#39;C:\Users\Eric000\dataSets\dat\user_artists.dat&#39;, sep&#x3D;&#39;\t&#39;)</span><br><span class="line">artists &#x3D; pd.read_csv(&#39;artists.dat&#39;,sep&#x3D;&#39;\t&#39;)</span><br><span class="line"></span><br><span class="line">ap &#x3D; pd.merge(</span><br><span class="line">  artists, plays,</span><br><span class="line">  how&#x3D;&quot;inner&quot;,</span><br><span class="line">  left_on&#x3D;&quot;id&quot;,</span><br><span class="line">  right_on&#x3D;&quot;artistID&quot;</span><br><span class="line">)</span><br><span class="line">ap &#x3D; ap.rename(columns&#x3D;&#123;&quot;weight&quot;: &quot;playCount&quot;&#125;)</span><br></pre></td></tr></table></figure>

<h6 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h6><p>通过pandas的groupby()对播放量的相关信息进行处理，并按照playCount降序排列。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">artist_rank &#x3D; ap.groupby([&#39;name&#39;]) \</span><br><span class="line">  .agg(&#123;&#39;userID&#39; : &#39;count&#39;, &#39;playCount&#39; : &#39;sum&#39;&#125;) \</span><br><span class="line">  .rename(columns&#x3D;&#123;&quot;userID&quot; : &#39;totalUniqueUsers&#39;, &quot;playCount&quot; : &quot;totalArtistPlays&quot;&#125;) \</span><br><span class="line">  .sort_values([&#39;totalArtistPlays&#39;], ascending&#x3D;False)</span><br><span class="line">artist_rank[&#39;avgUserPlays&#39;] &#x3D; artist_rank[&#39;totalArtistPlays&#39;] &#x2F; artist_rank[&#39;totalUniqueUsers&#39;]</span><br><span class="line"></span><br><span class="line">ap &#x3D; ap.join(artist_rank, on&#x3D;&quot;name&quot;, how&#x3D;&quot;inner&quot;) \</span><br><span class="line">  .sort_values([&#39;playCount&#39;], ascending&#x3D;False)</span><br></pre></td></tr></table></figure>

<h6 id="graphlab入场"><a href="#graphlab入场" class="headerlink" title="graphlab入场"></a>graphlab入场</h6><p>使用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ap.to_csv(&#39;artistsANDplays.csv&#39;)</span><br><span class="line"></span><br><span class="line">sf &#x3D; gl.SFrame(&#39;artistsANDplays.csv&#39;)</span><br><span class="line">sf.remove_columns([&#39;X1&#39;,&#39;id&#39;,&#39;url&#39;, &#39;pictureURL&#39;])</span><br></pre></td></tr></table></figure>

<p>将dfrmae输出为「artistsANDplays.csv」并实例化一个sFrme对象sf，通过remove_columns()删除暂时用不到的数据。</p>
<p><img src="https://version2.oss-cn-hangzhou.aliyuncs.com/img/20200526/1.png" alt="1"></p>
<h6 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h6><p>通过graphlab的canvas，我们可以非常容易地对数据进行可视化处理，这将及其简化我们的工作，不得不再次感叹python强大的工具库。</p>
<p>我们只需要将处理后的数据实例化为一个SFrame对象，即可通过鼠标的交互得到我们想要的可视化结果，免于手动使用代码绘制图像。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sf.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://version2.oss-cn-hangzhou.aliyuncs.com/img/20200526/2.png" alt="2"></p>
<p>总览</p>
<p><img src="https://version2.oss-cn-hangzhou.aliyuncs.com/img/20200526/3.png" alt="3"></p>
<p>总播放量对应的歌手</p>
<p><img src="https://version2.oss-cn-hangzhou.aliyuncs.com/img/20200526/image-20200602220058235.png" alt="image-20200602220058235"></p>
<p>有多少独立用户听过对应歌手的歌</p>
<p><img src="https://version2.oss-cn-hangzhou.aliyuncs.com/img/20200526/image-20200602220214830.png" alt="image-20200602220214830"></p>
<p>通过独立用户和总播放量的对应关系基本可以看出歌手的流行程度</p>
<p><img src="https://version2.oss-cn-hangzhou.aliyuncs.com/img/20200526/image-20200602220506766.png" alt="image-20200602220506766"></p>
<h6 id="推荐系统实现"><a href="#推荐系统实现" class="headerlink" title="推荐系统实现"></a>推荐系统实现</h6><p>为了实现协同过滤，我们将ap中的playCount转换为了一个矩阵，在处理过playCount以及通过assign和pivot两个方法后重新塑造dataframe后，「ratings」的概念逐渐清晰，我们将ratings赋值与[0-1]之间，基于原始数据的playCount构建了一个评价体系，并用0补齐数据缺失的地方。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">pc &#x3D; ap.playCount</span><br><span class="line">play_count_scaled &#x3D; (pc - pc.min()) &#x2F; (pc.max() - pc.min())</span><br><span class="line">ap &#x3D; ap.assign(playCountScaled&#x3D;play_count_scaled)</span><br><span class="line"></span><br><span class="line">ratings_df &#x3D; ap.pivot(</span><br><span class="line">    index&#x3D;&#39;userID&#39;,</span><br><span class="line">    columns&#x3D;&#39;artistID&#39;,</span><br><span class="line">    values&#x3D;&#39;playCountScaled&#39;</span><br><span class="line">)</span><br><span class="line">ratings &#x3D; ratings_df.fillna(0).values</span><br></pre></td></tr></table></figure>

<p>计算ratings矩阵的稀疏度</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sparsity &#x3D; float(len(ratings.nonzero()[0]))</span><br><span class="line">sparsity &#x2F;&#x3D; (ratings.shape[0] * ratings.shape[1])</span><br><span class="line">sparsity *&#x3D; 100</span><br><span class="line">print(&#39;&#123;:.2f&#125;%&#39;.format(sparsity))</span><br></pre></td></tr></table></figure>

<p>接下来我们通过重写后的sklearn.model_selection的train_test_split将ratings分为「训练组」和「校验组」，并用0代替了一些参考价值不大的rating。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">train, val &#x3D; train_test_split(ratings)</span><br><span class="line"></span><br><span class="line">MIN_USER_RATINGS &#x3D; 35</span><br><span class="line">DELETE_RATING_COUNT &#x3D; 15</span><br><span class="line">def train_test_split(ratings):</span><br><span class="line">    validation &#x3D; np.zeros(ratings.shape)</span><br><span class="line">    train &#x3D; ratings.copy()</span><br><span class="line">    for user in np.arange(ratings.shape[0]):</span><br><span class="line">        if len(ratings[user,:].nonzero()[0]) &gt;&#x3D; MIN_USER_RATINGS:</span><br><span class="line">            val_ratings &#x3D; np.random.choice(</span><br><span class="line">              ratings[user, :].nonzero()[0],</span><br><span class="line">              size&#x3D;DELETE_RATING_COUNT,</span><br><span class="line">              replace&#x3D;False</span><br><span class="line">            )</span><br><span class="line">            train[user, val_ratings] &#x3D; 0</span><br><span class="line">            validation[user, val_ratings] &#x3D; ratings[user, val_ratings]</span><br><span class="line">    return train, validation</span><br></pre></td></tr></table></figure>

<h6 id="测量误差"><a href="#测量误差" class="headerlink" title="测量误差"></a>测量误差</h6><p>我们采用「RMSE」即「均方根误差」来测量误差，通过这一算法，我们对真值和预测值的偏差有了一个大概的认识。</p>
<p><img src="https://version2.oss-cn-hangzhou.aliyuncs.com/img/20200526/image-20200602220925621.png" alt="image-20200602220925621"></p>
<h6 id="训练推荐系统"><a href="#训练推荐系统" class="headerlink" title="训练推荐系统"></a>训练推荐系统</h6><p>使用「SGD」即「随机梯度下降」训练，赋予未知对象预测值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">def fit(self, X_train, X_val):</span><br><span class="line">  m, n &#x3D; X_train.shape</span><br><span class="line">  self.P &#x3D; 3 * np.random.rand(self.n_latent_features, m)</span><br><span class="line">  self.Q &#x3D; 3 * np.random.rand(self.n_latent_features, n)</span><br><span class="line">  self.train_error &#x3D; []</span><br><span class="line">  self.val_error &#x3D; []</span><br><span class="line">  users, items &#x3D; X_train.nonzero()</span><br><span class="line">  for epoch in range(self.n_epochs):</span><br><span class="line">      for u, i in zip(users, items):</span><br><span class="line">          error &#x3D; X_train[u, i] - self.predictions(self.P[:,u], self.Q[:,i])</span><br><span class="line">          self.P[:, u] +&#x3D; self.learning_rate * \</span><br><span class="line">           (error * self.Q[:, i] - self.lmbda * self.P[:, u])</span><br><span class="line">          self.Q[:, i] +&#x3D; self.learning_rate * \</span><br><span class="line">           (error * self.P[:, u] - self.lmbda * self.Q[:, i])</span><br><span class="line">      train_rmse &#x3D; rmse(self.predictions(self.P, self.Q), X_train)</span><br><span class="line">      val_rmse &#x3D; rmse(self.predictions(self.P, self.Q), X_val)</span><br><span class="line">      self.train_error.append(train_rmse)</span><br><span class="line">      self.val_error.append(val_rmse)</span><br></pre></td></tr></table></figure>

<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><h6 id="评估推荐结果"><a href="#评估推荐结果" class="headerlink" title="评估推荐结果"></a>评估推荐结果</h6><p>在使用RMSE比较训练组和校验组，并且通过SGD训练模型之后，我们很直观的发现两个对照组之间的差距越来越小，训练时间与预测误差呈反比例关系，即训练时间越长，误差就越小。这也是我们推荐系统的<strong>评价标准</strong>，简而言之，当「训练组」和「校验组」的差距越来越小（即二者的重合程度越来越大时），我们的推荐系统也就越精确，即项目要求文档中的「<strong>推荐的精确度</strong>」。</p>
<p><img src="https://version2.oss-cn-hangzhou.aliyuncs.com/img/20200526/image-20200603100501243.png" alt="image-20200603100501243">·</p>
<h6 id="做出最后的推荐"><a href="#做出最后的推荐" class="headerlink" title="做出最后的推荐"></a>做出最后的推荐</h6><p>还记得上文中我们将矩阵中的一些对象置零吗，接下来，我们将用推荐系统获得的预测值将这些稀疏矩阵填充。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def predict(self, X_train, user_index):</span><br><span class="line">  y_hat &#x3D; self.predictions(self.P, self.Q)</span><br><span class="line">  predictions_index &#x3D; np.where(X_train[user_index, :] &#x3D;&#x3D; 0)[0]</span><br><span class="line">  return y_hat[user_index, predictions_index].flatten()</span><br></pre></td></tr></table></figure>

<p>这是预测前的结果</p>
<p><img src="https://version2.oss-cn-hangzhou.aliyuncs.com/img/20200526/image-20200602220555572.png" alt="image-20200602220555572"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">user_id &#x3D; 999</span><br><span class="line">user_index &#x3D; ratings_df.index.get_loc(user_id)</span><br><span class="line">predictions_index &#x3D; np.where(train[user_index, :] &#x3D;&#x3D; 0)[0]</span><br><span class="line">rating_predictions &#x3D; recommender.predict(train, user_index)</span><br><span class="line">existing_ratings_index &#x3D; np.where(train[user_index, :] &gt; 0)[0]</span><br><span class="line">existing_ratings &#x3D; train[user_index, existing_ratings_index]</span><br><span class="line">create_artist_ratings(</span><br><span class="line">  artists,</span><br><span class="line">  existing_ratings_index,</span><br><span class="line">  existing_ratings</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>这是预测后的结果</p>
<p><img src="https://version2.oss-cn-hangzhou.aliyuncs.com/img/20200526/image-20200602220616046.png" alt="image-20200602220616046"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">create_artist_ratings(</span><br><span class="line">  artists,</span><br><span class="line">  predictions_index,</span><br><span class="line">  rating_predictions</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>可以看出，id为999的用户，说不定不只是ColdPlay的忠实听众，Minnie Riperton或许也能让他在某个暗流涌动的寂寞之夜产生感官的愉悦。</p>
<p>「伟大的推荐系统诞生了」。</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] pandas-docs <a target="_blank" rel="noopener" href="https://pandas.pydata.org/pandas-docs">https://pandas.pydata.org/pandas-docs</a></p>
<p>[2] graphlab-docs <a target="_blank" rel="noopener" href="https://turi.com/products/create/docs/index.html">https://turi.com/products/create/docs/index.html</a></p>
<p>[3] Wikipedia</p>
<p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Root-mean-square_deviation">https://en.wikipedia.org/wiki/Root-mean-square_deviation</a></p>
<p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">https://en.wikipedia.org/wiki/Stochastic_gradient_descent</a></p>
<p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/SGD_(disambiguation)">https://en.wikipedia.org/wiki/SGD_(disambiguation)</a></p>
<p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Recommender_system">https://en.wikipedia.org/wiki/Recommender_system</a></p>
<p>and so on</p>
<p>[4] smartweed <a target="_blank" rel="noopener" href="https://www.cnblogs.com/smartweed/p/7210689.html">https://www.cnblogs.com/smartweed/p/7210689.html</a></p>
<p>[5] lastfm <a target="_blank" rel="noopener" href="https://www.last.fm/">https://www.last.fm/</a>.</p>
<p>[6] googlecolab <a target="_blank" rel="noopener" href="https://colab.research.google.com/">https://colab.research.google.com/</a></p>
<p>[7] google Scholar <a target="_blank" rel="noopener" href="https://scholar.google.com/">https://scholar.google.com</a></p>
<p>[8] StackOverflow</p>
<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/33000061/graphlab-create-canopy-runtime-exception-unable-to-evaluate-lambdas">https://stackoverflow.com/questions/33000061/graphlab-create-canopy-runtime-exception-unable-to-evaluate-lambdas</a></p>
<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/38983295/issues-downloading-graphlab-dependencies-get-dependencies?r=SearchResults">https://stackoverflow.com/questions/38983295/issues-downloading-graphlab-dependencies-get-dependencies?r=SearchResults</a></p>
<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/search?q=Downloading+xz">https://stackoverflow.com/search?q=Downloading+xz</a>.</p>
<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/44994717/import-graphlab-does-not-work-properly/45596896?r=SearchResults&amp;s=6">https://stackoverflow.com/questions/44994717/import-graphlab-does-not-work-properly/45596896?r=SearchResults&amp;s=6</a></p>
<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/25960070/graphlab-create-importerror-no-module-named-graphlab">https://stackoverflow.com/questions/25960070/graphlab-create-importerror-no-module-named-graphlab</a></p>
<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/38938236/attributeerror-module-object-has-no-attribute-sframe">https://stackoverflow.com/questions/38938236/attributeerror-module-object-has-no-attribute-sframe</a></p>
<p>and so on</p>
<p>[9] Music artist Recommender System using Stochastic Gradient Descent | Machine Learning from Scratch <a target="_blank" rel="noopener" href="https://www.curiousily.com/posts/music-artist-recommender-system-using-stochastic-gradient-descent/">https://www.curiousily.com/posts/music-artist-recommender-system-using-stochastic-gradient-descent/</a></p>
<p>[10] Various Implementations of Collaborative Filtering <a target="_blank" rel="noopener" href="https://towardsdatascience.com/various-implementations-of-collaborative-filtering-100385c6dfe0">https://towardsdatascience.com/various-implementations-of-collaborative-filtering-100385c6dfe0</a></p>
<p>[11] v2ex <a target="_blank" rel="noopener" href="https://v2ex.com/">https://v2ex.com</a></p>
<p>[12] github <a target="_blank" rel="noopener" href="https://github.com/">https://github.com</a></p>
<p>[13] Music Recommendation <a target="_blank" rel="noopener" href="https://www.kaggle.com/myonin/music-recommendation-random-forest-xgboost">https://www.kaggle.com/myonin/music-recommendation-random-forest-xgboost</a></p>
<p>[14] surprise-docs <a target="_blank" rel="noopener" href="https://surprise.readthedocs.io/en/stable/">https://surprise.readthedocs.io/en/stable/</a></p>
<p>[15] Building the optimal Book Recommender and measuring the role of Book Covers in predicting user ratings</p>

    </div>
    <div class="post-meta">
        
    <span class="post-time">二〇二〇年五月廿六日</span>
    </div>
</article>

<div class="prev_next">
    <nav id="prev_next">

<div class="prev">
    
    <p>上一篇</p>
    <a href="/2020/12/05/jotting/"><div class="article-nav-title">一次闲聊</div></a>
    
</div>
<div class="next">
    
    <p>下一篇</p>
    <a href="/2020/04/25/preference-right-power/"><div class="article-nav-title">偏好与权利及权力</div></a>
    
</div>

</nav>
</div>

<div class="post-comment">
    



</div>

    </main>
</body>

</html>